def predict(
        model,
        image: torch.Tensor,
        caption: str,
        box_threshold: float,
        text_threshold: float,
        device: str = "cuda",
        remove_combined: bool = False
) -> Tuple[torch.Tensor, torch.Tensor, List[str]]:
    caption = preprocess_caption(caption=caption)

    model = model.to(device)
    image = image.to(device)

    with torch.no_grad():
        outputs = model(image[None], captions=[caption])

    prediction_logits = outputs["pred_logits"].cpu().sigmoid()[0]  # prediction_logits.shape = (nq, 256)
    prediction_boxes = outputs["pred_boxes"].cpu()[0]  # prediction_boxes.shape = (nq, 4)

    mask = prediction_logits.max(dim=1)[0] > box_threshold
    logits = prediction_logits[mask]  # logits.shape = (n, 256)
    boxes = prediction_boxes[mask]  # boxes.shape = (n, 4)
    # Filter bounding boxes based on size
    max_width = .95
    max_height = .95
    min_width = .01
    min_height = .01
    min_yc = .2
    max_yc = .8
    print(boxes)
    size_mask = (boxes[:,2] <= max_width) & (boxes[:, 2] <= max_height) & (boxes[:,2] >= min_width) & (boxes[:, 2] >= min_height)
    boxes = boxes[size_mask]
    logits = logits[size_mask]
    # Filter based on box center
    #center_y = (boxes[:,1] + boxes[:,3]) / 2
    #print(center_y)
    #print(center_y <= 0.5)
    #if center_y > 0:
    #	center_y=center_y[0]
    #	loc_mask = (center_y >= min_yc) & (center_y <= max_yc)
    #	boxes = boxes[loc_mask]
    #	logits = logits[loc_mask]
    #	print(boxes)
    
    tokenizer = model.tokenizer
    tokenized = tokenizer(caption)
    
    if remove_combined:
        sep_idx = [i for i in range(len(tokenized['input_ids'])) if tokenized['input_ids'][i] in [101, 102, 1012]]
        
        phrases = []
        for logit in logits:
            max_idx = logit.argmax()
            insert_idx = bisect.bisect_left(sep_idx, max_idx)
            right_idx = sep_idx[insert_idx]
            left_idx = sep_idx[insert_idx - 1]
            phrases.append(get_phrases_from_posmap(logit > text_threshold, tokenized, tokenizer, left_idx, right_idx).replace('.', ''))
    else:
        phrases = [
            get_phrases_from_posmap(logit > text_threshold, tokenized, tokenizer).replace('.', '')
            for logit
            in logits
        ]

    return boxes, logits.max(dim=1)[0], phrases


